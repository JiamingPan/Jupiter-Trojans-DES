{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacerocks import SpaceRock\n",
    "import pandas as pd\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.time import Time\n",
    "import astropy.units as u\n",
    "import numpy as np\n",
    "from astropy.time import Time\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "import easyaccess as ea\n",
    "import matplotlib.pyplot as plt\n",
    "from DEEP_pointings import DEEP_fields_2019, DEEP_fields_2020\n",
    "from compute_chip import compute_chip\n",
    "from matplotlib.patches import Ellipse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astroquery.jplhorizons import Horizons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify known Jupiter Trojans in DES Y6A1 single exposure\n",
    "To identify JTs in DES data, we first obtain single exposures in DES Y6A1 that have known JTs within the field of view. The first step is to read in data from MPC of minor planets and save them as csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfo = pd.read_json('https://minorplanetcenter.net/Extended_Files/mpcorb_extended.json.gz') \n",
    "dfo.to_csv('mpcorb_extended.csv', index=None)\n",
    "dfo = pd.read_csv('mpcorb_extended.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the code for getting field of view of DECam and estimating whether the object is inside that field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DECamField(object):\n",
    "    def __init__(self, pos):\n",
    "        self.ra = pos.ra.deg\n",
    "        self.dec = pos.dec.deg\n",
    "\n",
    "    def ellipse(self):\n",
    "        # An approximation to the DECam field of view, suitable e.g. for plotting\n",
    "        semimajor_deg = 1.08\n",
    "        semiminor_deg = 0.98\n",
    "        center = (self.ra, self.dec)\n",
    "        rotation = 0\n",
    "        return Ellipse(center, 2*semimajor_deg, 2*semiminor_deg, rotation, fill=False, ec='k')\n",
    "    \n",
    "    def contains(self, ra1, dec1):\n",
    "        # returns True if the point (ra1, dec1) lies inside the field\n",
    "        radiff = ra1-self.ra\n",
    "        if radiff > 360: radiff -= 2*360\n",
    "        return radiff**2/1.08**2 + (dec1-self.dec)**2/0.98**2 <= 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code read in date, exposure number, and pointings of the DECam. It caculate the ephermis motions of known Jupiter Trojans (JTs) in MPC in the date of interest. Then, it returns the known JTs positions if they are within the field of DECam at the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_ccd(date,expnum,pointings):\n",
    "    df = dfo.loc[dfo.Orbit_type==\"Jupiter Trojan\"] #Known Jupiter Trojans in MPC\n",
    "    rocks = SpaceRock(a=df.a.values, \n",
    "                  e=df.e.values, \n",
    "                  inc=df.i.values, \n",
    "                  arg=df.Peri.values, \n",
    "                  node=df.Node.values, \n",
    "                  t_peri=df.Tp.values, \n",
    "                  epoch=df.Epoch.values,\n",
    "                  H=df.H.values, \n",
    "                  name=df.Principal_desig.values.astype(str),\n",
    "                  precise=False,\n",
    "                  coordinates='keplerian',\n",
    "                  angles='degrees',\n",
    "                  frame='heliocentric',\n",
    "                  obscode='W84')\n",
    "    dates = Time(date, format='iso', scale='utc')\n",
    "    prop1 = rocks.propagate(dates.jd, model=1) #Use space rock to derive the ephermis motions of known JTs.\n",
    "    obs1o = prop1.observe('W84')\n",
    "    df['ra'] =obs1o.ra.deg \n",
    "    df['dec'] =obs1o.dec.deg \n",
    "    df['expnum']=expnum\n",
    "    ccd = []\n",
    "    for ind, row in df.iterrows(): #Estimate whether the ephermis positions of knwon JTs are within the field of view of DECam.\n",
    "            target_pos = SkyCoord(row['ra'], row['dec'], frame='icrs', unit=(u.deg, u.deg))\n",
    "            ccdnam, ccdnum = compute_chip(target_pos.ra.radian, target_pos.dec.radian, pointings.ra.radian, pointings.dec.radian)\n",
    "            ccd.append(ccdnum)\n",
    "    df['ccd'] = ccd\n",
    "    df2 = df.loc[df.ccd>0] #Get the known JTs of those in the field\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we get date, pointing and exposure number from DES Y6A1 data. The format are changed to make sure they can be read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointing = pd.read_csv('DES pointing/DES_Y6A1_exposures.csv')\n",
    "pointgra = pointing['RADEG'].values.tolist()\n",
    "pointgdec = pointing['DECDEG'].values.tolist()\n",
    "point = []\n",
    "for i,j in zip(pointgra,pointgdec):\n",
    "    pointinge = SkyCoord(i, j, frame='icrs', unit=(u.deg, u.deg))\n",
    "    point.append(pointinge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointing = pd.read_csv('DES pointing/DES_Y6A1_exposures.csv')\n",
    "time = pointing['DATE_OBS']\n",
    "d = []\n",
    "for i in time:\n",
    "    a = i.replace(\"T\",\" \")\n",
    "    c = a.replace(\"b\",\"\")\n",
    "    e = eval(c)\n",
    "    d.append(e)\n",
    "time2 = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointing = pd.read_csv('DES pointing/DES_Y6A1_exposures.csv')\n",
    "expnum = pointing['EXPNUM'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desinfo = pd.DataFrame() #The pointings, exposure number, and data of DES Y6A1 single exposure.\n",
    "desinfo['telpos'] = point\n",
    "desinfo['expnum'] = expnum\n",
    "desinfo['date'] = time2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we run all the DES Y6A1 exposure to search for known JTs. The search is confined to ecliptic latitude from -30◦to 30◦. This requires a long time to run, so multiple notebooks were created and ran at once in moriarty. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = pd.DataFrame()\n",
    "for i in desinfolp: #The desinfo is run in multiple notebooks to make it faster.\n",
    "    dateten = i[2]\n",
    "    expnumten = i[1]\n",
    "    poten = i[0]\n",
    "    eclipticlat = poten.geocentrictrueecliptic.lat.deg\n",
    "    df2 = pd.DataFrame()\n",
    "    if eclipticlat < 30 and eclipticlat > -30:\n",
    "        df2 = give_ccd(date = dateten,expnum = expnumten,pointings= poten) \n",
    "        DESJTten = df2[['expnum','Principal_desig','ra', 'dec','ccd']]\n",
    "        dd = pd.concat([dd,DESJTten])\n",
    "    else: \n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtaining DES photometry\n",
    "Here we match identified JTs with Y6A1_FINALCUT_OBJECT objects to get photometry in DES. The object within 2'' of Y6A1_FINALCUT_OBJECT are selected. We excluded objects within 1'' that are in Y6A2_COADD_OBJECT_SUMMARY table, because they are likely to be stationary objects and are not of interest for your purpose. \n",
    "\n",
    "The Nepoch value is also extracted from Y6A2_COADD_OBJECT_SUMMARY table for objects within 1''. This value means the number of single exposure used for a COADD objects, and we find that if Nepoch value = 1, then the COADD object is likely to be a JT. Thus, coadd objects with Nepoch value smaller or equal to 1 but not all of them are zero are kept.\n",
    "\n",
    "At this stage, we obtained 12057 exposures corresponding to 888 unique objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def se_query(expnum,name,ra, dec, db=db):\n",
    "    one_arcsec = 1/3600.\n",
    "    query = f\"select y.ra, y.dec, y.band ,y.flux_auto, y.fluxerr_auto, y.expnum, y.nite, y.fwhm_world from Y6A1_FINALCUT_OBJECT y \\\n",
    "    where y.expnum={expnum} and y.ra between {ra}-2*{one_arcsec} and {ra}+2*{one_arcsec} \\\n",
    "    and y.dec between {dec}-2*{one_arcsec} and {dec}+2*{one_arcsec}\"\n",
    "    result = db.query_to_pandas(query) \n",
    "    result['name'] = name\n",
    "    return result\n",
    "\n",
    "def coadd_query(ra, dec, db=db):\n",
    "    one_arcsec = 1/3600.\n",
    "    query = f\"select c.ra, c.dec, c.flux_auto_g,c.flux_auto_i,c.flux_auto_r,c.flux_auto_y,\\\n",
    "    c.flux_auto_z,c.Nepochs_g,c.Nepochs_r,c.Nepochs_i,c.Nepochs_y,c.Nepochs_z from Y6A2_COADD_OBJECT_SUMMARY c \\\n",
    "    where c.ra between {ra}-{one_arcsec} and {ra}+{one_arcsec} and c.dec between {dec}-{one_arcsec} and {dec}+{one_arcsec} \\\n",
    "    and (c.Nepochs_g>1 or c.Nepochs_r>1 or c.Nepochs_i>1 or c.Nepochs_y>1 or c.Nepochs_z>1 or (c.Nepochs_g=0 and c.Nepochs_r=0 and c.Nepochs_i=0 and c.Nepochs_y=0 and c.Nepochs_z=0))\"\n",
    "    result = db.query_to_pandas(query)\n",
    "    return result\n",
    "\n",
    "sejt = pd.DataFrame()\n",
    "for pred in desjt: #a tuple with expnum and position.\n",
    "    expnum = pred[0]\n",
    "    name = pred[1]\n",
    "    ra = float(pred[2])\n",
    "    dec = float(pred[3])\n",
    "    df_se = se_query(expnum, name,ra, dec, db=db)\n",
    "    df_coadd = coadd_query(ra, dec, db=db)\n",
    "    df_se.to_csv()\n",
    "    if df_coadd.empty == True:\n",
    "        sejt = pd.concat([sejt,df_se])\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Nepoch_query(ra, dec, db=db):\n",
    "    one_arcsec = 1/3600.\n",
    "    query = f\"select c.Nepochs_g,c.Nepochs_r,c.Nepochs_i,c.Nepochs_y,c.Nepochs_z, c.dec, c.flux_auto_g,c.flux_auto_i,c.flux_auto_r,c.flux_auto_y,c.flux_auto_z from Y6A2_COADD_OBJECT_SUMMARY c \\\n",
    "    where c.ra between {ra}-{one_arcsec} and {ra}+{one_arcsec} and c.dec between {dec}-{one_arcsec} and {dec}+{one_arcsec}\"\n",
    "    result = db.query_to_pandas(query)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positions uncertainties of JTs\n",
    "Now we estimate positions uncertainties of JTs ephermis positions, and only choose those with < 2'' uncertainties in ra and dec. After contraining all the identified JTs to this criterion, we arrived at a number of  860 unique Jupiter Trojans with 11603 number of single exposures\n",
    "\n",
    "The time range is set to be within 1 second of the date of observation; as the JPL horizons needs to take a range of time for the estimation of uncertainties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desjt = pd.read_csv('DES_Trojans_mpc(2).csv') #File of JTs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = desjt.values.tolist()\n",
    "delta_ra = []\n",
    "delta_dec = []\n",
    "for i in a:\n",
    "    name = i[1] #name of JTs\n",
    "    i = i[11] #Time of the JTs\n",
    "    d = i.replace(\"T\",\" \")\n",
    "    c = d.replace(\"b\",\"\")\n",
    "    e = eval(c)\n",
    "    date = Time(e, format='iso', scale='utc') #Time of observaiton of JTs.\n",
    "    stopttime = starttime + 1*u.second \n",
    "    s = str(stopttime)\n",
    "    obj = Horizons(id=name, location='W84', #Calculate ephermis motions in JPL\n",
    "                epochs={'start':str(starttime), 'stop':str(s),\n",
    "                       'step':'1m'})\n",
    "    eph = obj.ephemerides()\n",
    "    delta_ra.append(eph['RA_3sigma']) #Store the uncertainties of JTs eperhmis motions from JPL\n",
    "    delta_dec.append(eph['DEC_3sigma'])\n",
    "delta_ra = np.array(delta_ra)\n",
    "delta_dec = np.array(delta_dec)\n",
    "delta_ra.ravel()\n",
    "delta_dec.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further constraints on the selected Trojans and photometry\n",
    "\n",
    "Here are the code to get zero point magniutde, apparent magniutde, and absolute magniutde. To further improve the quality of photometry, we require that the number of exposure of each Trojans to be bigger than 1 and magnitude error to be smaller than 0.1. \n",
    "\n",
    "After this, we obtain 269, 365, 307, and 237 L5 Trojans and 14,  13,  17,  and 12 L4 Trojans with r, g, i, and z band measurement respectively. Then the color color diagram, color magniutde, and color distributions can thus be analyzed for JTs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### zero point magniutde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_mag(expnum,ccd,band,db=db):\n",
    "    query = f\"select z.expnum,z.mag_zero,z.SIGMA_MAG_ZERO,z.band,z.ccdnum from Y6A1_ZEROPOINT z \\\n",
    "    where z.expnum={expnum} and z.band='{band}'and z.ccdnum={ccd}\"\n",
    "    result = db.query_to_pandas(query) \n",
    "    return result\n",
    "\n",
    "def zero_mag2(expnum,ccd,band,db=db):\n",
    "    query = f\"select z.expnum,z.mag_zero,z.SOURCE,z.VERSION,z.SIGMA_MAG_ZERO,z.band,z.ccdnum from Y3A2_ZEROPOINT z \\\n",
    "    where z.expnum={expnum} and z.band='{band}'and z.ccdnum={ccd} and z.VERSION = 'v2.0' and  z.source='FGCM'\"\n",
    "    result = db.query_to_pandas(query) \n",
    "    return result\n",
    "\n",
    "def zero_mag3(expnum,ccd,band,db=db):\n",
    "    query = f\"select z.expnum,z.mag_zero,z.SOURCE,z.VERSION,z.SIGMA_MAG_ZERO,z.band,z.ccdnum from Y3A2_ZEROPOINT z \\\n",
    "    where z.expnum={expnum} and z.band='{band}'and z.ccdnum={ccd} and z.VERSION = 'QUAT_2A' and  z.source='PGCM_FORCED'\"\n",
    "    result = db.query_to_pandas(query) \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain zero point magniutde from Y6A1_ZEROPOINT and Y3A2_ZEROPOINT. The zero point magnitudes are added to the original file of JTs and u and Y band measurements are not ocnsidered. Still missing 207 zero poing magniutde, and most of them are likely to be bad values, e.g. -9999."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desco = pd.read_csv('DES_JT_final_H&P.csv')\n",
    "desco = desco.loc[(desco['BAND']!='u')&(desco['BAND']!='Y')]\n",
    "noexp = pd.read_csv('DES_mis_m0.csv')\n",
    "noexp = flat(noexp.values.tolist())\n",
    "expn = pd.DataFrame()\n",
    "expnume = pd.DataFrame()\n",
    "expnume2 = pd.DataFrame()\n",
    "expnume3 = pd.DataFrame()\n",
    "exx = pd.DataFrame()\n",
    "a = 0\n",
    "rae= []\n",
    "dece= []\n",
    "bande= []\n",
    "expe= []\n",
    "namee= []\n",
    "ccde= []\n",
    "fluxe= []\n",
    "flux_errore= []\n",
    "nitee= []\n",
    "fhwme= []\n",
    "Lne= []\n",
    "missexp = []\n",
    "Hmage= []\n",
    "datee= []\n",
    "what=[]\n",
    "for i in desco.values.tolist():\n",
    "    exp = i[5];band = i[2];ccd = i[12];ra = i[0];dec = i[1];flux = i[3];flux_error= i[4];nite= i[6];fhwm= i[7];name = i[8];Ln = i[11];date = i[10];Hmag = i[9]\n",
    "    expnume = zero_mag(exp,ccd,band,db=db) #Primary\n",
    "    expnume2 = zero_mag2(exp,ccd,band,db=db) #secondary primary\n",
    "    expnume3 = zero_mag3(exp,ccd,band,db=db) #secondary seconary\n",
    "    if ((expnume['MAG_ZERO'].values<0)or (expnume.empty ==True)) and((expnume3['MAG_ZERO'].values<0)or (expnume3.empty ==True))and ((expnume2['MAG_ZERO'].values>0)):\n",
    "                rae.append(ra)\n",
    "                dece.append(dec)\n",
    "                bande.append(band)\n",
    "                expe.append(exp)\n",
    "                namee.append(name)\n",
    "                ccde.append(ccd)\n",
    "                fluxe.append(flux)\n",
    "                flux_errore.append(flux_error)\n",
    "                nitee.append(nite)\n",
    "                fhwme.append(fhwm)\n",
    "                Lne.append(Ln)\n",
    "                Hmage.append(Hmag)\n",
    "                datee.append(date)\n",
    "                expnume2.to_csv()\n",
    "                expn = pd.concat([expn,expnume2])\n",
    "    elif ((expnume['MAG_ZERO'].values<0)or (expnume.empty ==True)) and(expnume3['MAG_ZERO'].values>0) and (expnume2['MAG_ZERO'].values>0) :\n",
    "                rae.append(ra)\n",
    "                dece.append(dec)\n",
    "                bande.append(band)\n",
    "                expe.append(exp)\n",
    "                namee.append(name)\n",
    "                ccde.append(ccd)\n",
    "                fluxe.append(flux)\n",
    "                flux_errore.append(flux_error)\n",
    "                nitee.append(nite)\n",
    "                fhwme.append(fhwm)\n",
    "                Lne.append(Ln)\n",
    "                Hmage.append(Hmag)\n",
    "                datee.append(date)\n",
    "                expnume2.to_csv()\n",
    "                expn = pd.concat([expn,expnume2])\n",
    "    elif ((expnume['MAG_ZERO'].values<0)or (expnume.empty ==True)) and((expnume2['MAG_ZERO'].values<0)or (expnume2.empty ==True))and ((expnume3['MAG_ZERO'].values>0)):\n",
    "                rae.append(ra)\n",
    "                dece.append(dec)\n",
    "                bande.append(band)\n",
    "                expe.append(exp)\n",
    "                namee.append(name)\n",
    "                ccde.append(ccd)\n",
    "                fluxe.append(flux)\n",
    "                flux_errore.append(flux_error)\n",
    "                nitee.append(nite)\n",
    "                fhwme.append(fhwm)\n",
    "                Lne.append(Ln)\n",
    "                Hmage.append(Hmag)\n",
    "                datee.append(date)\n",
    "                expnume3.to_csv()\n",
    "                expn = pd.concat([expn,expnume3])\n",
    "    elif expnume['MAG_ZERO'].values>0:\n",
    "                rae.append(ra)\n",
    "                dece.append(dec)\n",
    "                bande.append(band)\n",
    "                expe.append(exp)\n",
    "                namee.append(name)\n",
    "                ccde.append(ccd)\n",
    "                fluxe.append(flux)\n",
    "                flux_errore.append(flux_error)\n",
    "                nitee.append(nite)\n",
    "                fhwme.append(fhwm)\n",
    "                Lne.append(Ln)\n",
    "                Hmage.append(Hmag)\n",
    "                datee.append(date)\n",
    "                expnume.to_csv()\n",
    "                expn = pd.concat([expn,expnume])\n",
    "    else: #Negative in Y6A1 and no valiue in Y3A2\n",
    "                what.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Store the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expn['ra'] = rae\n",
    "expn['dec'] = dece\n",
    "expn['band'] =bande\n",
    "expn['expnum'] =expe\n",
    "expn['name'] =namee\n",
    "expn['ccd'] =ccde\n",
    "expn['FLUX_AUTO'] =fluxe\n",
    "expn['FLUXERR_AUTO'] =flux_errore\n",
    "expn['NITE'] =nitee\n",
    "expn['FWHM_WORLD'] =fhwme\n",
    "expn['Ln'] =Lne\n",
    "expn['Date'] =datee\n",
    "expn['H'] =Hmage\n",
    "expn.to_csv('DES_JT_final_m0.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Absolute magnitude\n",
    "Then, I derive aboslute magniutde using space rock. First, the apparent magniutde is obatined from flux and zero point magniutd following m=m0 + log10(flux). \n",
    "\n",
    "Then, I match the name of each JTs with that of MPC to get their orbital parameters. The date and apparent magniutde are from our catalog and other parameters are from MPC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desco = pd.read_csv('DES_JT_final_m0.csv')\n",
    "for i in desco.values.tolist():\n",
    "    mag.append(-2.5*np.log10(i[13])+i[1])\n",
    "desco = pd.read_csv('DES_JT_final_m0.csv')\n",
    "desco['Apparent_Mag'] = mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = []\n",
    "Hg = []\n",
    "desco = pd.read_csv('DES_JT_final_m0.csv')\n",
    "for i in desco.values.tolist():\n",
    "    date  = i[18]\n",
    "    magg = i[20]\n",
    "    name = i[11]\n",
    "    a = date.replace(\"T\",\" \")\n",
    "    df = dfo.loc[dfo.Principal_desig==name]\n",
    "    rock = SpaceRock(a=df.a.values, \n",
    "                  e=df.e.values, \n",
    "                  inc=df.i.values, \n",
    "                  arg=df.Peri.values, \n",
    "                  node=df.Node.values, \n",
    "                  t_peri=df.Tp.values, \n",
    "                  epoch=a,\n",
    "                  name=df.Principal_desig.values.astype(str),\n",
    "                  mag= magg,\n",
    "                  precise=False,\n",
    "                  input_coordinates='keplerian',\n",
    "                  input_frame='heliocentric',\n",
    "                  input_angles='degrees',\n",
    "                  obscode='W84')\n",
    "    H = rock.calc_H(obscode='W84')\n",
    "    H = H[0]\n",
    "    H.ravel()\n",
    "    Hg.append(H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get absolute magniutde and its error for each JTs by taking the average over all of the exposures. \n",
    "Apparent magniutde is also derived in case needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ABmager(name,band,L):\n",
    "    desco = pd.read_csv('DES_JT_final_m0.csv')\n",
    "    desco = desco.values.tolist()\n",
    "    mager = []\n",
    "    mag = []\n",
    "    name = name\n",
    "    band = band\n",
    "    L = L\n",
    "    for i in desco:\n",
    "        if (name == i[11]) &(band==i[3])&(L==i[17]): #Match with one JT.\n",
    "            mager.append(i[14]**2) #FLux error\n",
    "            mag.append(i[13]) #FLux\n",
    "    magf = np.average(mag) \n",
    "    magfer = np.sqrt(np.sum(mager))/np.sqrt(len(mager))  \n",
    "    if len(mag)>1: #constraint that number of exposure > 1\n",
    "        magff =(-2.5/np.log(10))*(magfer/magf)  #Magnitude error\n",
    "    else:\n",
    "        magff = 0\n",
    "    return magff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hmag(name,band,L):\n",
    "    desco = pd.read_csv('DES_JT_final_m0.csv')\n",
    "    desco = desco.values.tolist()\n",
    "    mag = []\n",
    "    name = name\n",
    "    band = band\n",
    "    L = L\n",
    "    for i in desco:\n",
    "        if (name == i[11]) &(band==i[3])&(L==i[17]): \n",
    "            hh = i[20].replace(\"[\",\"\")\n",
    "            hh2 = hh.replace(\"]\",\"\")\n",
    "            mag.append(i[21])\n",
    "    if len(mag)>1: #With exposure more than 1 Nepoch requirement > 1\n",
    "        magff = np.average(mag)\n",
    "    else:\n",
    "        magff = 0\n",
    "    return magff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Apmag(name,band,L): #apparent mag\n",
    "    desco = pd.read_csv('DES_JT_final_m0.csv')\n",
    "    desco = desco.values.tolist()\n",
    "    mag = []\n",
    "    name = name\n",
    "    band = band\n",
    "    L = L\n",
    "    for i in desco:\n",
    "        if (name == i[11]) &(band==i[3])&(L==i[17])&(i[1]>0):\n",
    "            mag.append(np.array([i[20]]).astype(np.float))\n",
    "    if len(mag)>1: #With exposure more than 1\n",
    "        magff = np.average(mag)\n",
    "    else:\n",
    "        magff = 0\n",
    "    return magff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now store name, absolute magnitude, magniutde error, and apparent magniutde into a Panda datafram so they can plotted easily. This is for each band (g, r, i, z) and each cloud (L4 and L5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmag = pd.DataFrame()\n",
    "gg =  desco[(desco['BAND']=='g')&(desco['Ln']=='L5')]['name'].unique()\n",
    "JTmag_g_L5 = pd.DataFrame()\n",
    "ggmag=[]\n",
    "gpmag=[]\n",
    "ggmager=[]\n",
    "for i in gg:\n",
    "    mag = Hmag(name = i,band = 'g',L = 'L5')\n",
    "    ggmag.append(mag)\n",
    "    maga = Apmag(name = i,band = 'g',L = 'L5')\n",
    "    gpmag.append(maga)\n",
    "    mager = ABmager(name = i,band = 'g',L = 'L5')\n",
    "    ggmager.append(mager)\n",
    "JTmag_g_L5['name'] = gg\n",
    "JTmag_g_L5['magH_g'] = ggmag\n",
    "JTmag_g_L5['mag_ger'] = ggmager\n",
    "JTmag_g_L5['mag_g'] = gpmag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmag = pd.DataFrame()\n",
    "gg =  desco[(desco['BAND']=='g')&(desco['Ln']=='L4')]['name'].unique()\n",
    "JTmag_g_L4 = pd.DataFrame()\n",
    "ggmag=[]\n",
    "gpmag=[]\n",
    "ggmager=[]\n",
    "for i in gg:\n",
    "    mag = Hmag(name = i,band = 'g',L = 'L4')\n",
    "    ggmag.append(mag)\n",
    "    maga = Apmag(name = i,band = 'g',L = 'L4')\n",
    "    gpmag.append(maga)\n",
    "    mager = ABmager(name = i,band = 'g',L = 'L4')\n",
    "    ggmager.append(mager)\n",
    "JTmag_g_L4['name'] = gg\n",
    "JTmag_g_L4['magH_g'] = ggmag\n",
    "JTmag_g_L4['mag_ger'] = ggmager\n",
    "JTmag_g_L4['mag_g'] = gpmag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr =  desco[(desco['BAND']=='r')&(desco['Ln']=='L5')]['name'].unique()\n",
    "JTmag_r_L5 = pd.DataFrame()\n",
    "rmag=[]\n",
    "rpmag=[]\n",
    "rmager=[]\n",
    "for i in rr:\n",
    "    mag = Hmag(name = i,band = 'r',L = 'L5')\n",
    "    rmag.append(mag)\n",
    "    maga = Apmag(name = i,band = 'r',L = 'L5')\n",
    "    rpmag.append(maga)\n",
    "    mager = ABmager(name = i,band = 'r',L = 'L5')\n",
    "    rmager.append(mager)\n",
    "JTmag_r_L5['name'] = rr\n",
    "JTmag_r_L5['magH_r'] = rmag\n",
    "JTmag_r_L5['mag_rer'] = rmager\n",
    "JTmag_r_L5['mag_r'] = rpmag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr =  desco[(desco['BAND']=='r')&(desco['Ln']=='L4')]['name'].unique()\n",
    "JTmag_r_L4 = pd.DataFrame()\n",
    "rmag=[]\n",
    "rpmag=[]\n",
    "rmager=[]\n",
    "for i in rr:\n",
    "    mag = Hmag(name = i,band = 'r',L = 'L4')\n",
    "    rmag.append(mag)\n",
    "    maga = Apmag(name = i,band = 'r',L = 'L4')\n",
    "    rpmag.append(maga)\n",
    "    mager = ABmager(name = i,band = 'r',L = 'L4')\n",
    "    rmager.append(mager)\n",
    "JTmag_r_L4['name'] = rr\n",
    "JTmag_r_L4['magH_r'] = rmag\n",
    "JTmag_r_L4['mag_rer'] = rmager\n",
    "JTmag_r_L4['mag_r'] = rpmag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr =  desco[(desco['BAND']=='i')&(desco['Ln']=='L5')]['name'].unique()\n",
    "JTmag_i_L5 = pd.DataFrame()\n",
    "imag=[]\n",
    "ipmag=[]\n",
    "imager=[]\n",
    "for i in rr:\n",
    "    mag = Hmag(name = i,band = 'i',L = 'L5')\n",
    "    imag.append(mag)\n",
    "    maga = Apmag(name = i,band = 'i',L = 'L5')\n",
    "    ipmag.append(maga)\n",
    "    mager = ABmager(name = i,band = 'i',L = 'L5')\n",
    "    imager.append(mager)\n",
    "JTmag_i_L5['name'] = ii\n",
    "JTmag_i_L5['magH_i'] = imag\n",
    "JTmag_i_L5['mag_ier'] = imager\n",
    "JTmag_i_L5['mag_i'] = ipmag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii =  desco[(desco['BAND']=='i')&(desco['Ln']=='L4')]['name'].unique()\n",
    "JTmag_i_L4 = pd.DataFrame()\n",
    "imag=[]\n",
    "ipmag=[]\n",
    "imager=[]\n",
    "for i in rr:\n",
    "    mag = Hmag(name = i,band = 'i',L = 'L4')\n",
    "    imag.append(mag)\n",
    "    maga = Apmag(name = i,band = 'i',L = 'L4')\n",
    "    ipmag.append(maga)\n",
    "    mager = ABmager(name = i,band = 'i',L = 'L4')\n",
    "    imager.append(mager)\n",
    "JTmag_i_L4['name'] = ii\n",
    "JTmag_i_L4['magH_i'] = imag\n",
    "JTmag_i_L4['mag_ier'] = imager\n",
    "JTmag_i_L4['mag_i'] = ipmag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz =  desco[(desco['BAND']=='z')&(desco['Ln']=='L5')]['name'].unique()\n",
    "JTmag_z_L5 = pd.DataFrame()\n",
    "zmager=[]\n",
    "zpmag=[]\n",
    "zmag=[]\n",
    "for i in rr:\n",
    "    mag = Hmag(name = i,band = 'z',L = 'L5')\n",
    "    zmag.append(mag)\n",
    "    maga = Apmag(name = i,band = 'z',L = 'L5')\n",
    "    zpmag.append(maga)\n",
    "    mager = ABmager(name = i,band = 'z',L = 'L5')\n",
    "    zmager.append(mager)\n",
    "JTmag_z_L5['name'] = zz\n",
    "JTmag_z_L5['magH_z'] = zmag\n",
    "JTmag_z_L5['mag_zer'] = zmager\n",
    "JTmag_z_L5['mag_z'] = zpmag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz =  desco[(desco['BAND']=='z')&(desco['Ln']=='L4')]['name'].unique()\n",
    "JTmag_z_L4 = pd.DataFrame()\n",
    "zmag=[]\n",
    "zpmag=[]\n",
    "zmager=[]\n",
    "for i in zz:\n",
    "    mag = Hmag(name = i,band = 'z',L = 'L4')\n",
    "    zmag.append(mag)\n",
    "    maga = Apmag(name = i,band = 'z',L = 'L4')\n",
    "    zpmag.append(maga)\n",
    "    mager = ABmager(name = i,band = 'z',L = 'L4')\n",
    "    zmager.append(mager)\n",
    "JTmag_z_L4['name'] = zz\n",
    "JTmag_z_L4['magH_z'] = zmag\n",
    "JTmag_z_L4['mag_zer'] = zmager\n",
    "JTmag_z_L4['mag_z'] = zpmag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the code to plot color color diagram, and that of color magniutde diagram is similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#color color diagram. \n",
    "riL5s = []\n",
    "izL5s = []\n",
    "riL5ser = []\n",
    "izL5ser = []\n",
    "for a in JTmag_z_L5.values.tolist():\n",
    "    if (a[1]>0)and(np.fabs(a[2])<0.1):\n",
    "        name = a[0]\n",
    "        mag = a[1]\n",
    "        mager = a[2]\n",
    "        for b in JTmag_r_L5.values.tolist():\n",
    "            if (b[1]>0)and(np.fabs(b[2])<0.1):\n",
    "                name2 = b[0]\n",
    "                mag2 = b[1]\n",
    "                mag2er = b[2]\n",
    "                for c in JTmag_i_L5.values.tolist():\n",
    "                    if (c[1]>0)and(np.fabs(c[2])<0.1):\n",
    "                        name3 = c[0]\n",
    "                        mag3 = c[1]\n",
    "                        mag3er = c[2]\n",
    "                        if (name == name2)&(name3 == name2):\n",
    "                            iz = mag3 - mag\n",
    "                            ri = mag2 - mag3\n",
    "                            izer = np.sqrt(mager**2+mag3er**2)\n",
    "                            rier = np.sqrt(mag2er**2+mag3er**2)\n",
    "                            riL5ser.append(rier)\n",
    "                            izL5ser.append(izer)\n",
    "                            riL5s.append(ri)\n",
    "                            izL5s.append(iz)\n",
    "riL4s = []\n",
    "izL4s = []\n",
    "riL4ser = []\n",
    "izL4ser = []\n",
    "for a in JTmag_z_L4.values.tolist():\n",
    "    if (a[1]>0)and(np.fabs(a[2])<0.1):\n",
    "        name = a[0]\n",
    "        mag = a[1]\n",
    "        mager = a[2]\n",
    "        for b in JTmag_r_L4.values.tolist():\n",
    "            if (b[1]>0)and(np.fabs(b[2])<0.1):\n",
    "                name2 = b[0]\n",
    "                mag2 = b[1]\n",
    "                mag2er = b[2]\n",
    "                for c in JTmag_i_L4.values.tolist():\n",
    "                        if (c[1]>0) and(np.fabs(c[2])<0.1):\n",
    "                            name3 = c[0]\n",
    "                            mag3 = c[1]\n",
    "                            mag3er = c[2]\n",
    "                            if (name == name2)&(name3 == name2):\n",
    "                                iz = mag3 - mag\n",
    "                                ri = mag2 - mag3\n",
    "                                izer = np.sqrt(mager**2+mag3er**2)\n",
    "                                rier = np.sqrt(mag2er**2+mag3er**2)\n",
    "                                riL4ser.append(rier)\n",
    "                                izL4ser.append(izer)\n",
    "                                riL4s.append(ri)\n",
    "                                izL4s.append(iz)\n",
    "    \n",
    "\n",
    "plt.figure(figsize=(6,6),frameon=False)\n",
    "ax2=plt.subplot(111)\n",
    "plt.errorbar(riL5s, izL5s, xerr=riL5ser, yerr=izL5ser,  ms=5,fmt=\"o\", color=\"b\",lw=0.8 ,capsize=1,label='L5')\n",
    "plt.errorbar(riL4s, izL4s, xerr=riL4ser, yerr=izL4ser,  ms=5,fmt=\"o\", color=\"r\",lw=0.8 ,capsize=1,label='L4')\n",
    "plt.errorbar(0.12, 0.04, xerr=0.01, yerr=0.02,ms=10, fmt=\"v\", color=\"g\", capsize=2,label='Solar color')\n",
    "plt.xlabel('Hr-Hi')\n",
    "plt.title('ri/iz of Jupiter Trojans')\n",
    "plt.ylabel('Hi-Hz')\n",
    "plt.grid()\n",
    "ax2.legend(prop={'size': 10})\n",
    "plt.savefig('izri',bbox_inches='tight',transparent=False,dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python374jvsc74a57bd0c39b740c7e8315252f08c94b17875ec09dd6ee22a1ed05f98757d1ae325a54cb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
